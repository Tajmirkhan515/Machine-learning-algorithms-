{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7c3c37-118b-47f5-9e6f-8f1fa8caa1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "   total_bedrooms  total_rooms  population\n",
      "0             3.0            7         800\n",
      "1             NaN            5         600\n",
      "2             2.0            6        1200\n",
      "3             3.0            8         700\n",
      "4             NaN            5         650\n",
      "5             1.0            4         900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'total_bedrooms': [3, np.nan, 2, 3, np.nan, 1],\n",
    "    'total_rooms': [7, 5, 6, 8, 5, 4],\n",
    "    'population': [800, 600, 1200, 700, 650, 900]\n",
    "}\n",
    "\n",
    "housing = pd.DataFrame(data)\n",
    "\n",
    "# Print the initial DataFrame\n",
    "print(\"Initial DataFrame:\")\n",
    "print(housing)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d704cd44-994a-4b54-b0b9-061c943894a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., nan,  2.,  1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24953ed1-b6e2-4bfa-b48d-f7acee4202dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping rows with missing 'total_bedrooms':\n",
      "   total_bedrooms  total_rooms  population\n",
      "0             3.0            7         800\n",
      "2             2.0            6        1200\n",
      "3             3.0            8         700\n",
      "5             1.0            4         900\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Drop rows where \"total_bedrooms\" is missing\n",
    "housing_dropna = housing.dropna(subset=[\"total_bedrooms\"])\n",
    "print(\"\\nDataFrame after dropping rows with missing 'total_bedrooms':\")\n",
    "print(housing_dropna)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb20557a-b23f-49d4-9f67-c276f3d91e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping the 'total_bedrooms' column:\n",
      "   total_rooms  population\n",
      "0            7         800\n",
      "1            5         600\n",
      "2            6        1200\n",
      "3            8         700\n",
      "4            5         650\n",
      "5            4         900\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Drop the \"total_bedrooms\" column entirely\n",
    "housing_drop_column = housing.drop(\"total_bedrooms\", axis=1)\n",
    "print(\"\\nDataFrame after dropping the 'total_bedrooms' column:\")\n",
    "print(housing_drop_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17d7324-1cd8-4c89-8faa-9f5ac875d3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after filling missing 'total_bedrooms' with the median:\n",
      "   total_bedrooms  total_rooms  population\n",
      "0             3.0            7         800\n",
      "1             2.5            5         600\n",
      "2             2.0            6        1200\n",
      "3             3.0            8         700\n",
      "4             2.5            5         650\n",
      "5             1.0            4         900\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Fill missing values in \"total_bedrooms\" with the median\n",
    "median = housing[\"total_bedrooms\"].median()  # Calculate the median\n",
    "housing_fillna = housing.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "housing_fillna[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "print(\"\\nDataFrame after filling missing 'total_bedrooms' with the median:\")\n",
    "print(housing_fillna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712c25cd-43d0-4103-ba93-f94efb7bc29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# Handling Text and Categorical Attributes with different method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db6049b4-014b-4951-8f66-04feb4797319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After imputing Age with median:\n",
      "    Age  Gender\n",
      "0  25.0    Male\n",
      "1  35.0  Female\n",
      "2  35.0  Female\n",
      "3  45.0     NaN\n",
      "4  35.0    Male\n"
     ]
    }
   ],
   "source": [
    "////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#using second method\n",
    "\n",
    "# this is used for both, this is sklearn libaray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Sample DataFrame with numerical and categorical data\n",
    "data = {\n",
    "    'Age': [25, np.nan, 35, 45, np.nan],\n",
    "    'Gender': ['Male', 'Female', 'Female', np.nan, 'Male']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute numerical data (Age) with median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df['Age'] = num_imputer.fit_transform(df[['Age']])\n",
    "\n",
    "print(\"After imputing Age with median:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d857135-a041-474a-b821-31bc647bf31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After imputing:\n",
      "    Age  Gender\n",
      "0  25.0    Male\n",
      "1  35.0  Female\n",
      "2  35.0  Female\n",
      "3  45.0  Female\n",
      "4  35.0    Male\n"
     ]
    }
   ],
   "source": [
    "# Impute categorical data (Gender) with the most frequent value (mode)\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['Gender'] = cat_imputer.fit_transform(df[['Gender']]).ravel()  # Use ravel() to flatten the array\n",
    "\n",
    "print(\"After imputing:\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176aa938-cb25-4c46-8f6b-26e60022008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# using econding method\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16fbfd7b-c813-4391-8205-97922e2a75ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "  ocean_proximity  total_bedrooms\n",
      "0        NEAR BAY           471.0\n",
      "1          INLAND           371.0\n",
      "2      NEAR OCEAN           369.0\n",
      "3        NEAR BAY             NaN\n",
      "4          ISLAND           541.0\n",
      "5          INLAND           343.0\n",
      "6      NEAR OCEAN           507.0\n",
      "7        NEAR BAY           395.0\n",
      "8        NEAR BAY           478.0\n",
      "9      NEAR OCEAN           335.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder # this is used for categorical data, ordinal data, (e.g, Excellent, goods, bad)\n",
    "\n",
    "# Load the data\n",
    "data = pd.DataFrame({\n",
    "    'ocean_proximity': ['NEAR BAY', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'NEAR BAY', 'NEAR OCEAN'],\n",
    "    'total_bedrooms': [471, 371, 369, None, 541, 343, 507, 395, 478, 335]\n",
    "})\n",
    "\n",
    "# Display the data\n",
    "print(\"Original Data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "034f5fac-c722-47ab-8641-ffc6fa59f989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEAR BAY', 'INLAND', 'NEAR OCEAN', 'ISLAND'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[\"ocean_proximity\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06985ee4-909e-4d5d-a8c4-e2907923ff39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "NEAR BAY      4\n",
       "NEAR OCEAN    3\n",
       "INLAND        2\n",
       "ISLAND        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb1cb8bc-beca-47da-9dba-963f968272f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Data:\n",
      "  ocean_proximity  total_bedrooms  ocean_proximity_encoded\n",
      "0        NEAR BAY           471.0                      2.0\n",
      "1          INLAND           371.0                      0.0\n",
      "2      NEAR OCEAN           369.0                      3.0\n",
      "3        NEAR BAY           395.0                      2.0\n",
      "4          ISLAND           541.0                      1.0\n",
      "5          INLAND           343.0                      0.0\n",
      "6      NEAR OCEAN           507.0                      3.0\n",
      "7        NEAR BAY           395.0                      2.0\n",
      "8        NEAR BAY           478.0                      2.0\n",
      "9      NEAR OCEAN           335.0                      3.0\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "median = data[\"total_bedrooms\"].median()\n",
    "data[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "\n",
    "# Encode categorical variable\n",
    "housing_cat = data[[\"ocean_proximity\"]]\n",
    "ordinal_encoder = OrdinalEncoder() # used for ordinal data\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "\n",
    "# Add encoded data back to DataFrame\n",
    "data[\"ocean_proximity_encoded\"] = housing_cat_encoded\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"\\nUpdated Data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1795ced-60e2-4c5c-8e99-269697188822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "  ocean_proximity\n",
      "0        NEAR BAY\n",
      "1          INLAND\n",
      "2      NEAR OCEAN\n",
      "3        NEAR BAY\n",
      "4          ISLAND\n",
      "5          INLAND\n",
      "6      NEAR OCEAN\n",
      "7        NEAR BAY\n",
      "8        NEAR BAY\n",
      "9      NEAR OCEAN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder # this is used for categorical data, in categorical it must be nominal data, e.g(red, green, yello)\n",
    "\n",
    "# Load the data\n",
    "data = pd.DataFrame({\n",
    "    'ocean_proximity': ['NEAR BAY', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'NEAR BAY', 'NEAR OCEAN']\n",
    "})\n",
    "\n",
    "# Display the data\n",
    "print(\"Original Data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a3b7d5b-95b9-4b6e-ac42-83d8784fdef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded Data:\n",
      "  (0, 2)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 3)\t1.0\n",
      "  (7, 2)\t1.0\n",
      "  (8, 2)\t1.0\n",
      "  (9, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variable using OneHotEncoder\n",
    "housing_cat = data[[\"ocean_proximity\"]]\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "\n",
    "# Display the encoded data\n",
    "print(\"\\nEncoded Data:\")\n",
    "print(housing_cat_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fb5b235-20a9-442e-8bd8-ee3ba41115a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling: feature scalling is a technique to standardize the independent features present in the data in a fixed range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a52e6be1-6704-4764-ad7c-e6dc45061076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Data with two features\n",
    "data1 = pd.DataFrame({\n",
    "    'feature1': [10, 20, 30, 40, 1000],\n",
    "    'feature2': [1, 2, 3, 4, 5]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a2f22a6-07c2-425b-9da8-797323779657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    feature1  feature2\n",
      "0        10         1\n",
      "1        20         2\n",
      "2        30         3\n",
      "3        40         4\n",
      "4      1000         5\n",
      "\n",
      "Min-Max Scaled Data:\n",
      "    feature1  feature2\n",
      "0  0.000000      0.00\n",
      "1  0.010101      0.25\n",
      "2  0.020202      0.50\n",
      "3  0.030303      0.75\n",
      "4  1.000000      1.00\n"
     ]
    }
   ],
   "source": [
    "#Min-Max Scaling\n",
    "#How‐ever, Min-Max is much affected by outliers.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Min-Max Scaling xi=(xi-Xmin)/(xmax-Xmin)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data_min_max_scaled = min_max_scaler.fit_transform(data1)\n",
    "\n",
    "data_min_max_scaled_df = pd.DataFrame(data_min_max_scaled, columns=['feature1', 'feature2'])\n",
    "print(\"Original Data:\\n\", data1)\n",
    "print(\"\\nMin-Max Scaled Data:\\n\", data_min_max_scaled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1468e1ce-d082-445e-a956-16e5dd1ce700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized Data:\n",
      "    feature1  feature2\n",
      "0 -0.538285 -1.414214\n",
      "1 -0.512652 -0.707107\n",
      "2 -0.487019  0.000000\n",
      "3 -0.461387  0.707107\n",
      "4  1.999343  1.414214\n"
     ]
    }
   ],
   "source": [
    "#Standard Scaler : (xi-X)/standard devition\n",
    "#How‐ever, standardization is much less affected by outliers.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardization\n",
    "standard_scaler = StandardScaler()\n",
    "data_standard_scaled = standard_scaler.fit_transform(data1)\n",
    "\n",
    "data_standard_scaled_df = pd.DataFrame(data_standard_scaled, columns=['feature1', 'feature2'])\n",
    "print(\"\\nStandardized Data:\\n\", data_standard_scaled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c7eccc-4b81-4837-829e-13a6d6d04878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################################################################\n",
    "# Now this is time to Select and Train a Model,\n",
    " #Let’s first train a Linear Regression model, \n",
    "# let's see complete example from scratch.\n",
    "\n",
    "#Step 1: Load and Explore the Data\n",
    "#First, let's create a small dataset to work with:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample housing data\n",
    "data = {\n",
    "    'median_income': [2.3442, 8.3014, 5.6431, 3.8462, 4.0368],\n",
    "    'total_rooms': [5612, 7650, 720, 1501, 1454],\n",
    "    'housing_median_age': [29, 42, 25, 52, 36],\n",
    "    'median_house_value': [286600, 340600, 196900, 46300, 254500]\n",
    "}\n",
    "\n",
    "housing = pd.DataFrame(data)\n",
    "\n",
    "# Separate the features and the labels\n",
    "housing_labels = housing['median_house_value'].copy()\n",
    "housing = housing.drop('median_house_value', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9e4285-ea0d-4886-afcf-b44a24b25245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Prepare the Data\n",
    "#We need to preprocess the data before feeding it to the model. We'll use a pipeline to handle missing values and scaling.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define a pipeline for preprocessing\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Prepare the data\n",
    "housing_prepared = num_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74275609-d0df-4648-8ed2-1adc0cf42200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 3: Train the Model\n",
    "#Now let's train a Linear Regression model.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train the model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b66cdf-b4ac-4502-9d44-28ff763ca821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [302069.28378442 334341.83150204 233916.55983588  80863.50972959\n",
      " 173708.81514807]\n",
      "Labels: [286600, 340600, 196900, 46300, 254500]\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Make Predictions\n",
    "#Let's make predictions on a few instances from the training set.\n",
    "\n",
    "# Select a few instances for testing\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "\n",
    "# Prepare the data using the pipeline\n",
    "some_data_prepared = num_pipeline.transform(some_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lin_reg.predict(some_data_prepared)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ad8469-3dc0-41fd-bd26-402ec68926d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 43290.97104580214\n"
     ]
    }
   ],
   "source": [
    "#Step 5: Evaluate the Model\n",
    "#Measure the RMSE on the whole training set.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make predictions on the whole training set\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "\n",
    "# Calculate MSE and RMSE\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"RMSE:\", lin_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78181ac7-121f-432f-bfe5-0f7d567b0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison and Improvement\n",
    "#If the RMSE is high relative to the range of house prices, it suggests the model is not performing well. Possible improvements include:\n",
    "# this time it's high\n",
    "#Feature Engineering: Add new features that might help the model make better predictions.\n",
    "#Model Selection: Try more complex models such as Decision Trees, Random Forests, or Gradient Boosting.\n",
    "#Regularization: Apply regularization techniques to prevent overfitting.\n",
    "#By following these steps, you can better understand how MSE is calculated and how to interpret and improve the performance of your machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1353ceec-3455-447a-ae0a-2bc678ac97e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: Train the DecisionTreeRegressor\n",
    "\n",
    "# Train the DecisionTreeRegressor model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc77ee7c-bc05-45bc-b590-f98e84ded53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE on training set: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training set\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "\n",
    "# Calculate MSE and RMSE\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(\"Decision Tree RMSE on training set:\", tree_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f0eb8-df64-43ce-97a4-45ad24444021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
